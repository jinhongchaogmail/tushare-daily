import os
import sys
import time
import pandas as pd
import requests
import xcsc_tushare as ts
from datetime import datetime

# æ·»åŠ  shared åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥ feature_engineering
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'shared'))
try:
    from features import apply_technical_indicators
    HAS_FEATURE_ENGINE = True
except ImportError as e:
    print(f"âš ï¸ è­¦å‘Šï¼šæ— æ³•å¯¼å…¥ç‰¹å¾å·¥ç¨‹ ({e})ï¼Œå°†è·³è¿‡é¢„æµ‹åŠŸèƒ½", flush=True)
    HAS_FEATURE_ENGINE = False

# å°è¯•å¯¼å…¥ CatBoost
try:
    import catboost as cb
    import json
    HAS_MODEL = True
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæœªå®‰è£… catboostï¼Œå°†è·³è¿‡é¢„æµ‹åŠŸèƒ½", flush=True)
    HAS_MODEL = False

TUSHARE_TOKEN = os.environ.get("TUSHARE_TOKEN")
TS_SERVER = "http://116.128.206.39:7172"
TS_ENV = "prd"
START_DATE = "20220101"
OUT_DIR = "data"
MODEL_PATH = 'models/catboost_final_model.cbm'
PARAMS_PATH = 'models/final_model_params.json'
MIN_RETURN_THRESHOLD = 0.03

# å…¨å±€å˜é‡
model = None
vol_multiplier = 0.89
report = []
all_predictions = [] # å­˜å‚¨æ‰€æœ‰é¢„æµ‹ç»“æœï¼Œç”¨äºå¼ºåˆ¶è¾“å‡º
count_debug = 0

if not TUSHARE_TOKEN:
    raise RuntimeError("Missing env TUSHARE_TOKEN")

ts.set_token(TUSHARE_TOKEN)
pro = ts.pro_api(env=TS_ENV, server=TS_SERVER)
hist_fields = "trade_date,open,high,low,close,change,pct_chg,volume,amount"

def init_model():
    """åˆå§‹åŒ–é¢„æµ‹æ¨¡å‹"""
    global model, vol_multiplier
    
    if not HAS_MODEL or not HAS_FEATURE_ENGINE:
        return False
    
    if not os.path.exists(MODEL_PATH):
        print(f"âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {MODEL_PATH}ï¼Œè·³è¿‡é¢„æµ‹åŠŸèƒ½", flush=True)
        return False

    try:
        model = cb.CatBoostClassifier()
        model.load_model(MODEL_PATH)
        
        if os.path.exists(PARAMS_PATH):
            with open(PARAMS_PATH, 'r') as f:
                params = json.load(f)
                vol_multiplier = params.get('vol_multiplier_best', 0.89)
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œæ³¢åŠ¨ç‡ä¹˜æ•°: {vol_multiplier:.4f}", flush=True)
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}", flush=True)
        return False

def predict_stock(ts_code, df):
    """å¯¹å•åªè‚¡ç¥¨è¿›è¡Œé¢„æµ‹ (å¤šç©ºåŒå‘)"""
    global report, count_debug, all_predictions
    
    if model is None or len(df) < 60:
        if len(df) < 60:
            print(f"  [{ts_code}] æ•°æ®ä¸è¶³ ({len(df)}è¡Œ)ï¼Œè·³è¿‡é¢„æµ‹", flush=True)
        return

    try:
        # ç‰¹å¾å·¥ç¨‹
        df_features = apply_technical_indicators(df)
        latest_row = df_features.iloc[[-1]].copy()
        current_date = latest_row['trade_date'].values[0]
        
        # é¢„æµ‹
        prob = model.predict_proba(latest_row)[0]
        prob_down, prob_flat, prob_up = prob[0], prob[1], prob[2]
        
        # è°ƒè¯•è¾“å‡º
        count_debug += 1
        # å¦‚æœæ€»æ•°å°‘äº 200 (è°ƒè¯•æ¨¡å¼)ï¼Œåˆ™æ‰“å°æ‰€æœ‰é¢„æµ‹ç»“æœ
        if len(report) < 200 or count_debug <= 5 or count_debug % 200 == 0 or prob_up > 0.25:
            print(f"  [{ts_code}] é¢„æµ‹: è·Œ{prob_down:.2f} å¹³{prob_flat:.2f} æ¶¨{prob_up:.2f}", flush=True)

        # ç­–ç•¥é€»è¾‘
        current_vol = latest_row['volatility_factor'].values[0]
        if pd.isna(current_vol): 
            current_vol = 0.02
        
        implied_return = current_vol * vol_multiplier
        signal = "âšª è§‚æœ›"
        position = 0.0
        reason = ""
        is_candidate = False
        
        # æ”¶é›†æ‰€æœ‰é¢„æµ‹ç»“æœ (Debugç”¨)
        all_predictions.append({
            'ä»£ç ': ts_code,
            'æ—¥æœŸ': pd.to_datetime(current_date).strftime('%Y-%m-%d'),
            'ä¿¡å·': "Debug",
            'ä¸Šæ¶¨æ¦‚ç‡': f"{prob_up:.1%}",
            'ä¸‹è·Œæ¦‚ç‡': f"{prob_down:.1%}",
            'æ³¢åŠ¨ç‡': f"{current_vol:.1%}",
            'é¢„æœŸæ”¶ç›Š': f"{implied_return:.1%}",
            'å»ºè®®ä»“ä½': "0.0%",
            'ç†ç”±': "Debugè®°å½•",
            'prob_up_raw': prob_up,
            'prob_down_raw': prob_down,
            'max_prob': max(prob_up, prob_down)
        })
        
        # --- é˜ˆå€¼è®¾ç½® (åŸºäºæœ€æ–°æ¨¡å‹åˆ†æ: Down å‡†, Up ä¿å®ˆ) ---
        THRESHOLD_WATCH_UP = 0.28    # é™ä½åšå¤šé—¨æ§›
        THRESHOLD_STRONG_UP = 0.38   # å¼ºåŠ›åšå¤šé—¨æ§›
        THRESHOLD_WATCH_DOWN = 0.35  # åšç©ºé—¨æ§›
        THRESHOLD_STRONG_DOWN = 0.45 # å¼ºåŠ›åšç©ºé—¨æ§›

        # --- 1. åšå¤šä¿¡å· (Long) ---
        if prob_up > prob_down and prob_up > THRESHOLD_WATCH_UP:
            signal = "ğŸ”µ å…³æ³¨å¤š"
            reason = f"çœ‹æ¶¨({prob_up:.1%})"
            is_candidate = True
            
            # å¼ºåŠ›ä¹°å…¥æ¡ä»¶
            if prob_up > THRESHOLD_STRONG_UP and prob_up > prob_flat:
                if implied_return > MIN_RETURN_THRESHOLD:
                    signal = "ğŸ”´ å¼ºåŠ›åšå¤š"
                    position = min(1.0, 0.02 / (current_vol + 1e-5))
                    reason = f"é«˜èƒœç‡({prob_up:.0%}) é«˜èµ”ç‡(>{implied_return:.1%})"
                else:
                    signal = "ğŸŸ  æ½œä¼åšå¤š" # èƒœç‡é«˜ä½†æ³¢åŠ¨ç‡ä½
                    reason = f"é«˜èƒœç‡({prob_up:.0%}) ä½æ³¢åŠ¨"

        # --- 2. åšç©ºä¿¡å· (Short) ---
        elif prob_down > prob_up and prob_down > THRESHOLD_WATCH_DOWN:
            signal = "ğŸŸ¡ å…³æ³¨ç©º"
            reason = f"çœ‹è·Œ({prob_down:.1%})"
            is_candidate = True
            
            if prob_down > THRESHOLD_STRONG_DOWN and prob_down > prob_flat:
                signal = "ğŸŸ¢ å¼ºåŠ›åšç©º"
                reason = f"é«˜ç¡®ä¿¡åº¦({prob_down:.1%})"
                position = min(1.0, 0.02 / (current_vol + 1e-5))

        if is_candidate:
            item = {
                'ä»£ç ': ts_code,
                'æ—¥æœŸ': pd.to_datetime(current_date).strftime('%Y-%m-%d'),
                'ä¿¡å·': signal,
                'ä¸Šæ¶¨æ¦‚ç‡': f"{prob_up:.1%}",
                'ä¸‹è·Œæ¦‚ç‡': f"{prob_down:.1%}",
                'æ³¢åŠ¨ç‡': f"{current_vol:.1%}",
                'é¢„æœŸæ”¶ç›Š': f"{implied_return:.1%}",
                'å»ºè®®ä»“ä½': f"{position:.1%}",
                'ç†ç”±': reason,
                'prob_up_raw': prob_up,
                'prob_down_raw': prob_down,
                'max_prob': max(prob_up, prob_down)
            }
            report.append(item)
            if "å¼ºåŠ›" in signal:
                print(f"  !!! å‘ç°æœºä¼š [{ts_code}]: {signal} - {reason}", flush=True)

    except Exception as e:
        print(f"âŒ [{ts_code}] é¢„æµ‹å‡ºé”™: {e}", flush=True)
        import traceback
        traceback.print_exc()

def generate_report():
    """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š (åˆ†å¤šç©ºå±•ç¤º)"""
    today_str = datetime.now().strftime("%Y-%m-%d")
    report_path = "reports/strategy_report.md"
    
    if report:
        df_report = pd.DataFrame(report)
        
        # åˆ†ç¦»å¤šç©º
        df_long = df_report[df_report['ä¿¡å·'].str.contains('å¤š')].sort_values('prob_up_raw', ascending=False)
        df_short = df_report[df_report['ä¿¡å·'].str.contains('ç©º')].sort_values('prob_down_raw', ascending=False)
        
        # ç§»é™¤åŸå§‹æ’åºåˆ—ï¼Œä¿æŒè¡¨æ ¼æ•´æ´
        cols_to_drop = ['prob_up_raw', 'prob_down_raw', 'max_prob']
        df_long_display = df_long.drop(columns=cols_to_drop, errors='ignore')
        df_short_display = df_short.drop(columns=cols_to_drop, errors='ignore')
        
        print(f"\n=== æ¯æ—¥ç­–ç•¥æŠ¥å‘Š (æ€»è®¡: {len(df_report)}) ===", flush=True)
        print(f"å¤šå¤´æœºä¼š: {len(df_long)} | ç©ºå¤´æœºä¼š: {len(df_short)}", flush=True)
        
        os.makedirs(os.path.dirname(report_path), exist_ok=True)
        with open(report_path, "w") as f:
            f.write(f"# æ¯æ—¥é‡åŒ–ç­–ç•¥æŠ¥å‘Š ({today_str})\n\n")
            f.write(f"**æ€»è®¡å…¥é€‰**: {len(df_report)} (å¤šå¤´: {len(df_long)}, ç©ºå¤´: {len(df_short)})\n\n")
            
            f.write("## ğŸ”´ å¤šå¤´æœºä¼š (Top 50)\n")
            if not df_long.empty:
                f.write(df_long_display.head(50).to_markdown(index=False))
            else:
                f.write("æ— ç¬¦åˆæ¡ä»¶çš„å¤šå¤´æœºä¼šã€‚\n")
            
            f.write("\n\n## ğŸŸ¢ ç©ºå¤´æœºä¼š (Top 50)\n")
            if not df_short.empty:
                f.write(df_short_display.head(50).to_markdown(index=False))
            else:
                f.write("æ— ç¬¦åˆæ¡ä»¶çš„ç©ºå¤´æœºä¼šã€‚\n")
        
        csv_path = report_path.replace(".md", ".csv")
        # CSV ä¿ç•™åŸå§‹æ¦‚ç‡åˆ—ï¼Œæ–¹ä¾¿ç”¨æˆ·è‡ªå·±æ’åº
        df_report.sort_values('max_prob', ascending=False).to_csv(csv_path, index=False)
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_path} å’Œ {csv_path}", flush=True)
    else:
        print("â„¹ï¸ ä»Šæ—¥æ— ç¬¦åˆæ¡ä»¶çš„äº¤æ˜“æœºä¼š", flush=True)
        
        # --- å¼ºåˆ¶è¾“å‡º Top 10 (Debug) ---
        if all_predictions:
            print("âš ï¸ å¼ºåˆ¶è¾“å‡º Top 10 é¢„æµ‹ç»“æœ (å³ä½¿æœªè¾¾é˜ˆå€¼)", flush=True)
            df_all = pd.DataFrame(all_predictions)
            # æŒ‰æœ€å¤§æ¦‚ç‡æ’åº
            df_top = df_all.sort_values('max_prob', ascending=False).head(10)
            
            os.makedirs(os.path.dirname(report_path), exist_ok=True)
            with open(report_path, "w") as f:
                f.write(f"# æ¯æ—¥é‡åŒ–ç­–ç•¥æŠ¥å‘Š ({today_str}) - DEBUG MODE\n\n")
                f.write("âš ï¸ **æ³¨æ„**: ä»Šæ—¥æ— ç¬¦åˆé˜ˆå€¼çš„æœºä¼šã€‚ä»¥ä¸‹ä¸ºæ¦‚ç‡æœ€é«˜çš„ Top 10 è‚¡ç¥¨ (ä»…ä¾›è°ƒè¯•å‚è€ƒ)ã€‚\n\n")
                f.write(df_top.drop(columns=['prob_up_raw', 'prob_down_raw', 'max_prob'], errors='ignore').to_markdown(index=False))
            
            print(f"âœ… å¼ºåˆ¶æŠ¥å‘Šå·²ä¿å­˜: {report_path}", flush=True)
        else:
            os.makedirs(os.path.dirname(report_path), exist_ok=True)
            with open(report_path, "w") as f:
                f.write(f"# æ¯æ—¥é‡åŒ–ç­–ç•¥æŠ¥å‘Š ({today_str})\n\n")
                f.write("ä»Šæ—¥æ— ç¬¦åˆæ¡ä»¶çš„äº¤æ˜“æœºä¼šï¼Œä¸”æ— ä»»ä½•æœ‰æ•ˆé¢„æµ‹æ•°æ®ã€‚")

def get_hist(ts_code: str):
    """è·å–å†å²æ•°æ®ï¼Œè‹¥æ•°æ®ä¸è¶³åˆ™è¿”å› None"""
    try:
        df = pro.daily(ts_code=ts_code, start_date=START_DATE, end_date="", fields=hist_fields)
    except Exception as e:
        raise e
        
    df = df.iloc[::-1].reset_index(drop=True)
    if len(df) > 21:  # è‡³å°‘ä¸€ä¸ªæœˆçš„æ•°æ®
        df["trade_date"] = pd.to_datetime(df["trade_date"], format="%Y%m%d")
        return ts_code, df
    else:
        return None

def list_main_board_cs():
    """è·å–ä¸»æ¿å·²ä¸Šå¸‚è‚¡ç¥¨åˆ—è¡¨"""
    today = datetime.today().strftime("%Y%m%d")
    temp0 = pro.stock_basic(market="CS", fields="ts_code,name,list_date,delist_date,list_board_name")
    temp0 = temp0[temp0["delist_date"].isna()]  # æœªé€€å¸‚
    temp0 = temp0[temp0["list_board_name"] == "ä¸»æ¿"]  # ä¸»æ¿
    temp0 = temp0[temp0["list_date"] <= today]  # å·²ç»ä¸Šå¸‚
    return temp0[["ts_code", "name"]].reset_index(drop=True)

def add_features(df: pd.DataFrame) -> pd.DataFrame:
    """æ·»åŠ æŠ€æœ¯æŒ‡æ ‡"""
    df["ma5"] = df["close"].rolling(5).mean()
    df["ma10"] = df["close"].rolling(10).mean()
    df["ma20"] = df["close"].rolling(20).mean()
    df["volatility_10"] = df["close"].rolling(10).std()
    df["vol_ma5"] = df["volume"].rolling(5).mean()
    df["momentum_5"] = df["close"].pct_change(5)
    delta = df["close"].diff()
    up = delta.clip(lower=0)
    down = -1 * delta.clip(upper=0)
    roll_up = up.rolling(14).mean()
    roll_down = down.rolling(14).mean()
    rs = roll_up / (roll_down + 1e-9)
    df["rsi14"] = 100 - (100 / (1 + rs))
    ema12 = df["close"].ewm(span=12, adjust=False).mean()
    ema26 = df["close"].ewm(span=26, adjust=False).mean()
    df["macd"] = ema12 - ema26
    df["macd_signal"] = df["macd"].ewm(span=9, adjust=False).mean()
    return df

def downcast(df: pd.DataFrame) -> pd.DataFrame:
    """é™ä½æµ®ç‚¹ç²¾åº¦ä»¥èŠ‚çœç©ºé—´"""
    for col in df.select_dtypes(include=["float64"]).columns:
        df[col] = df[col].astype("float32")
    return df

def main():
    print("ğŸš€ å¯åŠ¨æ•°æ®ä¸‹è½½ä¸é¢„æµ‹è„šæœ¬ (å•çº¿ç¨‹æ¨¡å¼)...", flush=True)
    os.makedirs(OUT_DIR, exist_ok=True)
    
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    model_enabled = init_model()
    if model_enabled:
        print("ğŸ“Š é¢„æµ‹åŠŸèƒ½å·²å¯ç”¨", flush=True)
    else:
        print("ğŸ“Š é¢„æµ‹åŠŸèƒ½æœªå¯ç”¨ï¼Œä»…ä¸‹è½½æ•°æ®", flush=True)
    
    print("ğŸ“‹ æ­£åœ¨è·å–è‚¡ç¥¨åˆ—è¡¨...", flush=True)
    try:
        ts_codes = list_main_board_cs()
    except Exception as e:
        print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}", flush=True)
        return

    print(f"âœ… è·å–åˆ° {len(ts_codes)} åªè‚¡ç¥¨ï¼Œå¼€å§‹å¤„ç†...", flush=True)
    
    # --- è°ƒè¯•æ¨¡å¼ï¼šé™åˆ¶å¤„ç†æ•°é‡ ---
    # ä¸ºäº†å¿«é€ŸéªŒè¯ï¼Œä»…å¤„ç†å‰ 100 åªè‚¡ç¥¨
    ts_codes = ts_codes.head(100)
    print(f"âš ï¸ è°ƒè¯•æ¨¡å¼å·²å¼€å¯ï¼šä»…å¤„ç†å‰ {len(ts_codes)} åªè‚¡ç¥¨", flush=True)
    
    total = len(ts_codes)
    skipped = []
    
    for idx, row in ts_codes.iterrows():
        ts_code = row["ts_code"]
        
        # è¿›åº¦æ‰“å°
        if idx % 50 == 0:
            print(f"[{idx}/{total}] æ­£åœ¨å¤„ç†: {ts_code}", flush=True)
            
        i = None
        retry = 0
        max_retry = 3

        while i is None and retry < max_retry:
            try:
                i = get_hist(ts_code)
                if i is None:
                    skipped.append(ts_code)
                    break
            except requests.exceptions.ConnectionError:
                print(f"âš ï¸ {ts_code} ç½‘ç»œé”™è¯¯ï¼Œ3ç§’åé‡è¯•", flush=True)
                time.sleep(3)
                retry += 1
                continue
            except Exception as e:
                print(f"âŒ {ts_code} å‡ºé”™: {e}ï¼Œè·³è¿‡", flush=True)
                skipped.append(ts_code)
                break

        if i is not None:
            code, df = i
            try:
                # é¢„æµ‹ï¼ˆåœ¨ä¿å­˜å‰ï¼‰
                if model_enabled and model is not None:
                    predict_stock(code, df.copy())
                
                # æ·»åŠ ç‰¹å¾å¹¶ä¿å­˜
                df = add_features(df)
                df = downcast(df)
                out_file = os.path.join(OUT_DIR, f"{code}.parquet")
                df.to_parquet(out_file, engine="pyarrow", compression="zstd", compression_level=3, index=False)
            except Exception as e:
                print(f"âŒ {ts_code} å¤„ç†æ•°æ®å‡ºé”™: {e}", flush=True)
                skipped.append(ts_code)

    if skipped:
        pd.DataFrame(skipped, columns=["ts_code"]).to_csv("skipped.csv", index=False)
        print(f"âš ï¸ è·³è¿‡ {len(skipped)} ä¸ªè‚¡ç¥¨ï¼Œå·²å†™å…¥ skipped.csv", flush=True)

    # ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
    if model_enabled and model is not None:
        generate_report()

    print("ğŸ‰ RUN_DONE: æ‰€æœ‰ä»»åŠ¡å®Œæˆ", flush=True)

if __name__ == "__main__":
    main()
